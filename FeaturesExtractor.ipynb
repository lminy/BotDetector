{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_fake = [\"FSF\", \"INT\", \"TWT\"]\n",
    "datasets_hum = [\"TFP\", \"E13\"]\n",
    "datasets = datasets_hum + datasets_fake\n",
    "folder_datasets = \"./datasets/\"\n",
    "file_users = \"users.csv\"\n",
    "file_tweets = \"tweets.csv\"\n",
    "file_friends = \"friends.csv\"\n",
    "file_followers = \"followers.csv\"\n",
    "features_file = \"features.json\"\n",
    "features_name_file = \"features_name.json\"\n",
    "target_file = \"target.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "users = pd.read_csv(folder_datasets + datasets[0] + '/' + file_users)\n",
    "tweets = pd.read_csv(folder_datasets + datasets[0] + '/' + file_tweets)\n",
    "friends = pd.read_csv(folder_datasets + datasets[0] + '/' + file_friends)\n",
    "followers = pd.read_csv(folder_datasets + datasets[0] + '/' + file_followers)\n",
    "for dataset in datasets[1:]:\n",
    "    users = pd.concat([users, pd.read_csv(folder_datasets + dataset + '/' + file_users)])\n",
    "    tweets = pd.concat([tweets, pd.read_csv(folder_datasets + dataset + '/' + file_tweets)])\n",
    "    friends = pd.concat([friends, pd.read_csv(folder_datasets + dataset + '/' + file_friends)])\n",
    "    followers = pd.concat([followers, pd.read_csv(folder_datasets + dataset + '/' + file_followers)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 10\n",
    "X = list()\n",
    "y = list()\n",
    "features_name = list()\n",
    "nb_fake_acc =0\n",
    "# Compute features for each Twitter account\n",
    "for index, user in users.iterrows():\n",
    "    acc_feat = OrderedDict()\n",
    "    #if index > SAMPLE_SIZE:\n",
    "    #    break\n",
    "    \n",
    "    # Class A (Profile)\n",
    "    #===================\n",
    "    acc_feat['has_name'] = int(user['name'] not in ['NULL', 'NaN', '', ' ', pd.np.nan])\n",
    "    acc_feat['has_image'] = int(user['default_profile_image'] != 1)\n",
    "    acc_feat['has_address'] = int(user['location'] not in ['NULL', 'NaN', '', ' ', pd.np.nan])\n",
    "    acc_feat['has_biography'] = int(user['description'] not in ['NULL', 'NaN', '', ' ', pd.np.nan])\n",
    "    acc_feat['followers_ge_30'] = int(user['followers_count'] >= 30)\n",
    "    acc_feat['belongs_to_a_list'] = int(user['listed_count'] > 0)\n",
    "    acc_feat['nb_tweets_ge_50'] = int(tweets.loc[tweets['user_id'] == user['id']].size >= 50)\n",
    "    acc_feat['url_in_profile'] = int(user['url'] not in ['NULL', 'NaN', '', ' ', pd.np.nan])\n",
    "    acc_feat['followers_2_times_ge_friends'] = int(2 * user['followers_count'] >= user['friends_count'])\n",
    "    \n",
    "    acc_feat['bot_in_biography'] = int(type(user['description']) is str and 'bot' in user['description'].lower())\n",
    "    acc_feat['ratio_friends_followers_around_100'] = int(user['followers_count'] > 0 and 80.0 <= float(user['friends_count']) / user['followers_count'] >= 120.0)\n",
    "    acc_feat['duplicate_profile_picture'] = int(users.loc[users['default_profile_image'] == user['default_profile_image']].size > 1)\n",
    "    \n",
    "    acc_feat['ratio_friends_followers_ge_50'] = int(user['followers_count'] > 0 and float(user['friends_count']) / user['followers_count'] >= 50)\n",
    "    acc_feat['default_image_after_2_month'] = int(user['default_profile_image'] == 1 and (datetime.datetime.now() - datetime.datetime.strptime(user['created_at'],'%a %b %d %H:%M:%S +0000 %Y')) > datetime.timedelta(weeks=4)) \n",
    "    acc_feat['friends_ge_100'] = int(user['friends_count'] >= 100)\n",
    "    acc_feat['no_bio'] = int(user['description'] in ['NULL', 'NaN', '', ' ', pd.np.nan])\n",
    "    acc_feat['no_location'] = int(user['location'] in ['NULL', 'NaN', '', ' ', pd.np.nan])\n",
    "    acc_feat['no_tweets'] = int(tweets.loc[tweets['user_id'] == user['id']].size == 0)\n",
    "    \n",
    "    acc_feat['nb_friends'] = int(user['friends_count'])\n",
    "    acc_feat['nb_tweets'] = int(tweets.loc[tweets['user_id'] == user['id']].size)\n",
    "    acc_feat['ratio_friends_followers_square'] = float(user['friends_count']) / pow(user['followers_count'], 2) if user['followers_count'] > 0 else 0\n",
    "    \n",
    "    acc_feat['age'] = (datetime.datetime.now() - datetime.datetime.strptime(user['created_at'],'%a %b %d %H:%M:%S +0000 %Y')).total_seconds()\n",
    "    acc_feat['following_rate'] = float(user['friends_count']) / age\n",
    "    \n",
    "    target = 1 if user['dataset'] in datasets_fake else 0\n",
    "    nb_fake_acc = nb_fake_acc + target\n",
    "    \n",
    "    y.append(target)\n",
    "    X.append(list(acc_feat.values()))\n",
    "    features_name = list(acc_feat.keys())\n",
    "nb_hum_acc = abs(len(y) - nb_fake_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL accounts: 180234\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1466, 67089, 5.7370898357435176e-05, 350123444.107283, 7.116335562518837e-06]\n",
      "# fake accounts: 3351\n",
      "# human accounts: 1950\n"
     ]
    }
   ],
   "source": [
    "print(\"TOTAL accounts: \" + str(users.size))\n",
    "#print(\"Features name: \" + str(list(features_name)))\n",
    "print(X[0])\n",
    "print(\"# fake accounts: \" + str(nb_fake_acc))\n",
    "print(\"# human accounts: \" + str(nb_hum_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle & balance the whole dataset (50-50 human/fake accounts)\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "max_sample = min(nb_fake_acc, nb_hum_acc) # max_sample = 1950 in our case\n",
    "X, y = X[:max_sample], y[:max_sample]\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store features on disk\n",
    "import json\n",
    "with open(features_file, 'w') as dstfile :\n",
    "    json.dump(X, dstfile)\n",
    "with open(target_file, 'w') as dstfile :\n",
    "    json.dump(y, dstfile)\n",
    "with open(features_name_file, 'w') as dstfile :\n",
    "    json.dump(features_name, dstfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                      0\n",
       "name                                    0\n",
       "screen_name                             0\n",
       "statuses_count                          0\n",
       "followers_count                         0\n",
       "friends_count                           0\n",
       "favourites_count                        0\n",
       "listed_count                            0\n",
       "created_at                              0\n",
       "url                                   235\n",
       "lang                                    0\n",
       "time_zone                             101\n",
       "location                              145\n",
       "default_profile                       314\n",
       "default_profile_image                 454\n",
       "geo_enabled                           230\n",
       "profile_image_url                       0\n",
       "profile_banner_url                    249\n",
       "profile_use_background_image           26\n",
       "profile_background_image_url_https      0\n",
       "profile_text_color                      0\n",
       "profile_image_url_https                 0\n",
       "profile_sidebar_border_color            0\n",
       "profile_background_tile               367\n",
       "profile_sidebar_fill_color              0\n",
       "profile_background_image_url            0\n",
       "profile_background_color                0\n",
       "profile_link_color                      0\n",
       "utc_offset                            101\n",
       "protected                             469\n",
       "verified                              469\n",
       "description                           125\n",
       "updated                                 0\n",
       "dataset                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
