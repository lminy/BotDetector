{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BotDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = \"features.json\"\n",
    "features_name_file = \"features_name.json\"\n",
    "target_file = \"target.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features: 1950\n",
      "features name: ['has_name', 'has_image', 'has_address', 'has_biography', 'followers_ge_30', 'belongs_to_a_list', 'nb_tweets_ge_50', 'url_in_profile', 'followers_2_times_ge_friends', 'bot_in_biography', 'ratio_friends_followers_around_100', 'duplicate_profile_picture', 'ratio_friends_followers_ge_50', 'default_image_after_2_month', 'friends_ge_100', 'no_bio', 'no_location', 'no_tweets', 'nb_friends', 'nb_tweets', 'ratio_friends_followers_square', 'age', 'following_rate']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(features_file, 'r') as f :\n",
    "    X = json.loads(f.read())\n",
    "with open(target_file, 'r') as f :\n",
    "    y = json.loads(f.read())\n",
    "with open(features_name_file, 'r') as f :\n",
    "    features_name = json.loads(f.read())\n",
    "print(\"# of features: \" + str(len(X)))\n",
    "print(\"features name: \" + str(features_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divise dataset\n",
    "def divide_dataset(X, y) :\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = divide_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "def train(classifier, name, param_grid=None) :\n",
    "    start_time = time.time()\n",
    "    if param_grid == None :\n",
    "        classifier.fit(X_train, y_train)\n",
    "        results[name] = dict(model=classifier)\n",
    "    else :\n",
    "        grid = GridSearchCV(classifier, param_grid, cv=10, scoring='accuracy', n_jobs=2) # Do a 10-fold cross validation\n",
    "        grid.fit(X, y) # fit the grid with data\n",
    "        results[name] = dict(grid=grid, model=classifier)\n",
    "    #total_time = datetime.datetime.fromtimestamp(time.time() - start_time)\n",
    "    total_time = datetime.timedelta(seconds=time.time() - start_time)\n",
    "    print(\"Training time : \" + str(total_time))#.strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:05.334686\n"
     ]
    }
   ],
   "source": [
    "name = \"k-NN\"\n",
    "classifier = KNeighborsClassifier(weights='uniform')\n",
    "k_range = list(range(1, 31)) # list of parameter values to test\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:03.146888\n"
     ]
    }
   ],
   "source": [
    "name = \"Decision tree\"\n",
    "classifier = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "d_range = list(range(1, 31)) # list of parameter values to test\n",
    "#s_range = list(range(2, 10))\n",
    "param_grid = dict(max_depth=d_range)#, min_samples_split=s_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.013054\n"
     ]
    }
   ],
   "source": [
    "name = \"NB - Gaussian\"\n",
    "classifier = GaussianNB()\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.017592\n"
     ]
    }
   ],
   "source": [
    "name = \"NB - Multinomial\"\n",
    "classifier = MultinomialNB()\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.006829\n"
     ]
    }
   ],
   "source": [
    "name = \"NB - Bernoulli\"\n",
    "classifier = BernoulliNB()\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-02   1.00000000e-01   1.00000000e+00   1.00000000e+01\n",
      "   1.00000000e+02   1.00000000e+03   1.00000000e+04   1.00000000e+05\n",
      "   1.00000000e+06   1.00000000e+07   1.00000000e+08   1.00000000e+09\n",
      "   1.00000000e+10]\n",
      "[  1.00000000e-09   1.00000000e-08   1.00000000e-07   1.00000000e-06\n",
      "   1.00000000e-05   1.00000000e-04   1.00000000e-03   1.00000000e-02\n",
      "   1.00000000e-01   1.00000000e+00   1.00000000e+01   1.00000000e+02\n",
      "   1.00000000e+03]\n",
      "Training time : 0:04:00.932656\n"
     ]
    }
   ],
   "source": [
    "name = \"SVM - SVC\"\n",
    "classifier = svm.SVC()\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "print(C_range)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "print(gamma_range)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:17.783268\n"
     ]
    }
   ],
   "source": [
    "name = \"SVM - Linear\"\n",
    "classifier = svm.LinearSVC()\n",
    "C_range = range(170,230,5)\n",
    "C_range = range(1,200,10)\n",
    "param_grid = dict(C=C_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:06.649900\n"
     ]
    }
   ],
   "source": [
    "name = \"Random forest\"\n",
    "classifier = RandomForestClassifier()\n",
    "d_range = list(range(1, 31)) # list of parameter values to test\n",
    "#s_range = list(range(2, 10))\n",
    "param_grid = dict(max_depth=d_range)#, min_samples_split=s_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.243003\n"
     ]
    }
   ],
   "source": [
    "name = \"AdaBoost\"\n",
    "classifier = AdaBoostClassifier(n_estimators=100)\n",
    "#param_grid = dict(max_depth=d_range)#, min_samples_split=s_range)\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.022902\n"
     ]
    }
   ],
   "source": [
    "name = \"Log. Regression\"\n",
    "classifier = LogisticRegression()\n",
    "#param_grid = dict(max_depth=d_range)#, min_samples_split=s_range)\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.022906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "name = \"Neural net\"\n",
    "#classifier = MLPClassifier(alpha=1)\n",
    "classifier = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN tn=207 fp=29 fn=92 tp=316\n",
      "Decision tree tn=228 fp=8 fn=11 tp=397\n",
      "NB - Gaussian tn=148 fp=88 fn=23 tp=385\n",
      "NB - Multinomial tn=150 fp=86 fn=13 tp=395\n",
      "NB - Bernoulli tn=205 fp=31 fn=16 tp=392\n",
      "Random forest tn=234 fp=2 fn=8 tp=400\n",
      "SVM - SVC tn=224 fp=12 fn=105 tp=303\n",
      "AdaBoost tn=226 fp=10 fn=8 tp=400\n",
      "Log. Regression tn=140 fp=96 fn=7 tp=401\n",
      "Neural net tn=0 fp=236 fn=0 tp=408\n",
      "SVM - Linear tn=0 fp=236 fn=0 tp=408\n",
      "+------------------+------------+----------+-----------+--------+-------+-------+-------+\n",
      "|      Model       | Best score | accuracy | precision | recall |  F-M. |  MCC  |  AUC  |\n",
      "+------------------+------------+----------+-----------+--------+-------+-------+-------+\n",
      "|  Random forest   |   0.986    |  0.984   |   0.995   |  0.98  | 0.988 | 0.967 | 0.986 |\n",
      "|  Decision tree   |   0.981    |   0.97   |    0.98   | 0.973  | 0.977 | 0.937 |  0.97 |\n",
      "|     AdaBoost     |   0.972    |  0.972   |   0.976   |  0.98  | 0.978 |  0.94 | 0.969 |\n",
      "|  NB - Bernoulli  |   0.927    |  0.927   |   0.927   | 0.961  | 0.943 | 0.842 | 0.915 |\n",
      "| NB - Multinomial |   0.846    |  0.846   |   0.821   | 0.968  | 0.889 | 0.669 | 0.802 |\n",
      "| Log. Regression  |    0.84    |   0.84   |   0.807   | 0.983  | 0.886 | 0.661 | 0.788 |\n",
      "|    SVM - SVC     |   0.828    |  0.818   |   0.962   | 0.743  | 0.838 | 0.667 | 0.846 |\n",
      "|  NB - Gaussian   |   0.828    |  0.828   |   0.814   | 0.944  | 0.874 | 0.623 | 0.785 |\n",
      "|       k-NN       |   0.827    |  0.812   |   0.916   | 0.775  | 0.839 |  0.63 | 0.826 |\n",
      "|   SVM - Linear   |   0.651    |  0.634   |   0.634   |  1.0   | 0.776 |   -1  |  0.5  |\n",
      "|    Neural net    |   0.634    |  0.634   |   0.634   |  1.0   | 0.776 |   -1  |  0.5  |\n",
      "+------------------+------------+----------+-----------+--------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "import operator\n",
    "from sklearn import metrics\n",
    "import math\n",
    "t = PrettyTable(['Model', 'Best score', 'accuracy', 'precision', 'recall', 'F-M.', 'MCC', 'AUC'])#'FP', 'TN', 'FN', 'TP'])\n",
    "for clf_name, result in results.items() :\n",
    "    model = result['model']\n",
    "    if 'grid' in result :\n",
    "        grid = result['grid']\n",
    "        score = grid.best_score_\n",
    "        # Compute false positives and false negatives\n",
    "        model.__init__(**grid.best_params_)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        #print(result.best_estimator_)\n",
    "    else : # For non grid_search models\n",
    "        #training_error = clf.score(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    print(clf_name + \" tn=\" + str(tn) + \" fp=\" + str(fp) + \" fn=\" + str(fn) + \" tp=\" + str(tp))\n",
    "    accuracy = float(tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    recall = float(tp) / (tp + fn) # a.k.a. sensitivity\n",
    "    f_measure = float(2 * precision * recall) / (precision + recall)\n",
    "    mcc = -1\n",
    "    if fp!=0 and tp != 0 and tn != 0 and fn!= 0:\n",
    "        mcc = float(tp * tn - fp * fn) / math.sqrt(float(tp+fn) * (tp+fp) * (tn+fp) * (tn+fn)) # Matthew Correlation Coefficient\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    t.add_row([clf_name, round(score, 3), round(accuracy, 3), round(precision,3), round(recall,3), round(f_measure,3), round(mcc,3), round(auc,3)]) #fp, tn, fn, tp])\n",
    "\n",
    "        \n",
    "print(t.get_string(sort_key=operator.itemgetter(2, 1), sortby=\"Best score\", reversesort=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
