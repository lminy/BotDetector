{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BotDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import config as c\n",
    "use_only_class_a = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features: 5301\n",
      "features name: ['has_name', 'has_image', 'has_address', 'has_biography', 'followers_ge_30', 'belongs_to_a_list', 'nb_tweets_ge_50', 'url_in_profile', 'followers_2_times_ge_friends', 'bot_in_biography', 'ratio_friends_followers_around_100', 'duplicate_profile_picture', 'ratio_friends_followers_ge_50', 'default_image_after_2_month', 'friends_ge_100', 'no_bio', 'no_location', 'no_tweets', 'nb_friends', 'nb_tweets', 'ratio_friends_followers_square', 'age', 'following_rate']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import json\n",
    "\n",
    "if use_only_class_a:\n",
    "    folder_features = c.folder_class_a\n",
    "else:\n",
    "    folder_features = c.folder_class_a_b_c\n",
    "\n",
    "with open(folder_features + c.file_features, 'r') as f :\n",
    "    X = json.loads(f.read())\n",
    "with open(folder_features + c.file_target, 'r') as f :\n",
    "    y = json.loads(f.read())\n",
    "with open(folder_features + c.file_features_name, 'r') as f :\n",
    "    features_name = json.loads(f.read())\n",
    "\n",
    "print(\"# of features: \" + str(len(X)))\n",
    "print(\"features name: \" + str(features_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divise dataset\n",
    "def divide_dataset(X, y) :\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "X_train, X_test, y_train, y_test = divide_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "def train(classifier, name, param_grid=None) :\n",
    "    start_time = time.time()\n",
    "    if param_grid == None :\n",
    "        classifier.fit(X_train, y_train)\n",
    "        results[name] = dict(model=classifier)\n",
    "    else :\n",
    "        grid = GridSearchCV(classifier, param_grid, cv=10, scoring='accuracy', n_jobs=2) # Do a 10-fold cross validation\n",
    "        grid.fit(X, y) # fit the grid with data\n",
    "        results[name] = dict(grid=grid, model=classifier)\n",
    "    #total_time = datetime.datetime.fromtimestamp(time.time() - start_time)\n",
    "    total_time = datetime.timedelta(seconds=time.time() - start_time)\n",
    "    print(\"Training time : \" + str(total_time))#.strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:04.669401\n"
     ]
    }
   ],
   "source": [
    "name = \"k-NN\"\n",
    "classifier = KNeighborsClassifier(weights='uniform')\n",
    "k_range = list(range(1, 31)) # list of parameter values to test\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:03.023080\n"
     ]
    }
   ],
   "source": [
    "name = \"Decision tree\"\n",
    "classifier = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "d_range = list(range(1, 31)) # list of parameter values to test\n",
    "#s_range = list(range(2, 10))\n",
    "param_grid = dict(max_depth=d_range)#, min_samples_split=s_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.006423\n"
     ]
    }
   ],
   "source": [
    "name = \"NB - Gaussian\"\n",
    "classifier = GaussianNB()\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.014110\n"
     ]
    }
   ],
   "source": [
    "name = \"NB - Multinomial\"\n",
    "classifier = MultinomialNB()\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.009180\n"
     ]
    }
   ],
   "source": [
    "name = \"NB - Bernoulli\"\n",
    "classifier = BernoulliNB()\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:03:39.888917\n"
     ]
    }
   ],
   "source": [
    "name = \"SVM - SVC\"\n",
    "classifier = svm.SVC()\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "#print(C_range)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "#print(gamma_range)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"SVM - Linear\"\n",
    "classifier = svm.LinearSVC()\n",
    "C_range = range(170,230,5)\n",
    "C_range = range(1,200,10)\n",
    "param_grid = dict(C=C_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:05.930685\n"
     ]
    }
   ],
   "source": [
    "name = \"Random forest\"\n",
    "classifier = RandomForestClassifier()\n",
    "d_range = list(range(1, 31)) # list of parameter values to test\n",
    "#s_range = list(range(2, 10))\n",
    "param_grid = dict(max_depth=d_range)#, min_samples_split=s_range)\n",
    "train(classifier, name, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.249278\n"
     ]
    }
   ],
   "source": [
    "name = \"AdaBoost\"\n",
    "classifier = AdaBoostClassifier(n_estimators=100)\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.016620\n"
     ]
    }
   ],
   "source": [
    "name = \"Log. Regression\"\n",
    "classifier = LogisticRegression()\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time : 0:00:00.020805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "name = \"Neural net\"\n",
    "#classifier = MLPClassifier(alpha=1)\n",
    "classifier = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "train(classifier, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+----------+-----------+--------+-------+-------+-------+\n",
      "|      Model       | Best score | accuracy | precision | recall |  F-M. |  MCC  |  AUC  |\n",
      "+------------------+------------+----------+-----------+--------+-------+-------+-------+\n",
      "|  Random forest   |   0.988    |  0.984   |    1.0    | 0.976  | 0.988 |   -1  | 0.988 |\n",
      "|  Decision tree   |   0.982    |  0.988   |   0.998   | 0.983  |  0.99 | 0.973 | 0.989 |\n",
      "|     AdaBoost     |    0.98    |   0.98   |    1.0    | 0.969  | 0.984 |   -1  | 0.984 |\n",
      "|  NB - Bernoulli  |   0.949    |  0.949   |   0.949   | 0.974  | 0.961 | 0.887 | 0.938 |\n",
      "|  NB - Gaussian   |    0.88    |   0.88   |    0.86   | 0.974  | 0.914 | 0.737 | 0.841 |\n",
      "| Log. Regression  |    0.88    |   0.88   |   0.859   | 0.976  | 0.914 | 0.737 |  0.84 |\n",
      "| NB - Multinomial |   0.879    |  0.879   |   0.857   | 0.976  | 0.913 | 0.734 | 0.838 |\n",
      "|    SVM - SVC     |   0.842    |  0.821   |   0.975   | 0.744  | 0.844 | 0.676 | 0.854 |\n",
      "|       k-NN       |   0.836    |   0.82   |   0.942   |  0.77  | 0.847 | 0.652 | 0.841 |\n",
      "|    Neural net    |   0.649    |  0.649   |   0.649   |  1.0   | 0.787 |   -1  |  0.5  |\n",
      "|   SVM - Linear   |   0.596    |  0.649   |   0.649   |  1.0   | 0.787 |   -1  |  0.5  |\n",
      "+------------------+------------+----------+-----------+--------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "import operator\n",
    "from sklearn import metrics\n",
    "import math\n",
    "t = PrettyTable(['Model', 'Best score', 'accuracy', 'precision', 'recall', 'F-M.', 'MCC', 'AUC'])#'FP', 'TN', 'FN', 'TP'])\n",
    "for clf_name, result in results.items() :\n",
    "    model = result['model']\n",
    "    if 'grid' in result :\n",
    "        grid = result['grid']\n",
    "        score = grid.best_score_\n",
    "        # Compute false positives and false negatives\n",
    "        model.__init__(**grid.best_params_)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        #print(result.best_estimator_)\n",
    "    else : # For non grid_search models\n",
    "        #training_error = clf.score(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    #print(clf_name + \" tn=\" + str(tn) + \" fp=\" + str(fp) + \" fn=\" + str(fn) + \" tp=\" + str(tp))\n",
    "    accuracy = float(tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = float(tp) / (tp + fp)\n",
    "    recall = float(tp) / (tp + fn) # a.k.a. sensitivity\n",
    "    f_measure = float(2 * precision * recall) / (precision + recall)\n",
    "    mcc = -1\n",
    "    if fp!=0 and tp != 0 and tn != 0 and fn!= 0:\n",
    "        mcc = float(tp * tn - fp * fn) / math.sqrt(float(tp+fn) * (tp+fp) * (tn+fp) * (tn+fn)) # Matthew Correlation Coefficient\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    t.add_row([clf_name, round(score, 3), round(accuracy, 3), round(precision,3), round(recall,3), round(f_measure,3), round(mcc,3), round(auc,3)]) #fp, tn, fn, tp])\n",
    "\n",
    "        \n",
    "print(t.get_string(sort_key=operator.itemgetter(2, 1), sortby=\"Best score\", reversesort=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
